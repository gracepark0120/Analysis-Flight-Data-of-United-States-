{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO List:\\n[] Find the same flight schedule and see if they are similarly delayed\\n[] Arrange delayed flights and delayed time by arrival/departure hub\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO List:\n",
    "[] Arrange delayed flights and delayed time by arrival/departure hub\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType,IntegerType\n",
    "from pyspark.sql.functions import UserDefinedFunction, to_timestamp\n",
    "from pyspark.sql.functions import collect_list,split,regexp_replace,col,round,concat,lit,avg,when,length,abs\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "#formats time to more readable format\n",
    "@udf(returnType = StringType())\n",
    "def modify_time(time):\n",
    "    year = str(int(time[0:4]) - 2000)\n",
    "    month = time[5:7]\n",
    "    day = time[8:10]\n",
    "    hour = time[11:13]\n",
    "    day_night = \"AM\"\n",
    "    if (int(hour) > 12):\n",
    "        hour = str(int(hour) - 12)\n",
    "        day_night = \"PM\"\n",
    "    return month + \"/\" + day + \"/\" + year + \" \" + hour + time[13:19] + \" \" + day_night\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\")\\\n",
    "    .appName('flight-data')\\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/home/ubuntu/postgresql-42.5.0.jar\")\\\n",
    "    .getOrCreate()\n",
    "# flight_data = spark.read.format(\"json\").options(inferschema='true',header='true').load('../part1/flights/flights_000.jsonl')\n",
    "flight_data = spark.read.format(\"json\").options(inferschema='true',header='true').load('../part1/flights/')\n",
    "flight_data = flight_data.select('@acid', '@airline', '@arrArpt', '@depArpt',\\\n",
    "                                 'fdm:trackInformation.nxcm:qualifiedAircraftId.nxce:igtd',\\\n",
    "                                 'fdm:trackInformation.nxcm:ncsmTrackData.nxcm:eta.@timeValue',\\\n",
    "                                 'fdm:trackInformation.nxcm:ncsmTrackData.nxcm:arrivalFixAndTime.@arrTime')\n",
    "# renames the table columns\n",
    "new_column_names = [\"Flight Number\", \"Airline\", \"Arrival Airport\", \"Departure Airport\", \"Departure Time\", \"Scheduled Arrival Time\", \"Actual Arrival Time\"]\n",
    "flight_data = flight_data.toDF(*new_column_names)\n",
    "# removing invalid departure and arrival times, null values\n",
    "flight_data = flight_data.na.drop()\n",
    "\n",
    "# removes placeholder letter in front of airport code, if it exists\n",
    "flight_data = flight_data.withColumn('Arrival Airport', when(length(col('Arrival Airport')) == 4, col('Arrival Airport').substr(2,3))\\\n",
    "                         .otherwise(col('Arrival Airport')))\\\n",
    "                         .withColumn('Departure Airport', when(length(col('Departure Airport')) == 4, col('Departure Airport').substr(2,3))\\\n",
    "                         .otherwise(col('Departure Airport')))\\\n",
    "                         .withColumn('Delayed', to_timestamp(flight_data[\"Scheduled Arrival Time\"]).cast('long') < to_timestamp(flight_data[\"Actual Arrival Time\"]).cast('long'))\\\n",
    "                         .withColumn('Delay Time', when(to_timestamp(flight_data[\"Scheduled Arrival Time\"]).cast('long') < to_timestamp(flight_data[\"Actual Arrival Time\"]).cast('long'),\\\n",
    "                            abs(to_timestamp(flight_data[\"Scheduled Arrival Time\"]).cast('long') - to_timestamp(flight_data[\"Actual Arrival Time\"]).cast('long')))\\\n",
    "                            .otherwise(\"N/A\"))\\\n",
    "                         .withColumn('Departure Time', modify_time(col('Departure Time')))\\\n",
    "                         .withColumn('Scheduled Arrival Time', modify_time(col('Scheduled Arrival Time')))\\\n",
    "                         .withColumn('Actual Arrival Time', modify_time(col('Actual Arrival Time')))\n",
    "\n",
    "\n",
    "# combine with ticket price data\n",
    "fares = spark.read.parquet('./ticket_fares/output.parquet/')\n",
    "flight_data = flight_data.join(fares, (flight_data.Airline == fares.Airline) \n",
    "                            & (flight_data['Arrival Airport'] == fares.Origin)\n",
    "                            & (flight_data['Departure Airport'] == fares.Dest))\\\n",
    "                    .drop(fares.Airline).drop('ItinID', 'Origin', 'Dest','Passengers', 'ItinFare')\\\n",
    "                    .dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:=====================================================>(196 + 2) / 198]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+---------------+-----------------+--------------------+----------------------+--------------------+-------+----------+--------+\n",
      "|Flight Number|Airline|Arrival Airport|Departure Airport|      Departure Time|Scheduled Arrival Time| Actual Arrival Time|Delayed|Delay Time|Distance|\n",
      "+-------------+-------+---------------+-----------------+--------------------+----------------------+--------------------+-------+----------+--------+\n",
      "|       ASA790|    ASA|            EWR|              SEA|10/22/22 04:50:00 AM|  10/22/22 09:50:30 AM|10/22/22 09:32:10 AM|  false|       N/A|  2402.0|\n",
      "|      DAL2077|    DAL|            ATL|              BOI|10/22/22 05:58:00 AM|  10/22/22 09:51:55 AM|10/22/22 09:34:24 AM|  false|       N/A|  1838.0|\n",
      "|       ASA315|    ASA|            DFW|              SEA|10/22/22 06:20:00 AM|  10/22/22 09:43:51 AM|10/22/22 09:30:41 AM|  false|       N/A|  1660.0|\n",
      "|       DAL881|    DAL|            CVG|              LAX|10/22/22 06:50:00 AM|  10/22/22 10:48:43 AM|10/22/22 10:44:10 AM|  false|       N/A|  1900.0|\n",
      "|      UAL2185|    UAL|            EWR|              SMF|10/22/22 06:47:00 AM|  10/22/22 11:35:00 AM|10/22/22 11:24:20 AM|  false|       N/A|  2500.0|\n",
      "|       AAL548|    AAL|            CLT|              JAX|10/22/22 09:15:00 AM|  10/22/22 10:15:21 AM|10/22/22 10:02:49 AM|  false|       N/A|   328.0|\n",
      "|      AAL1850|    AAL|            CLT|              ONT|10/22/22 05:59:00 AM|  10/22/22 09:51:11 AM|10/22/22 09:37:44 AM|  false|       N/A|  2078.0|\n",
      "|       UAL706|    UAL|            TPA|              LAX|10/22/22 05:48:00 AM|  10/22/22 09:54:52 AM|10/22/22 09:40:54 AM|  false|       N/A|  2158.0|\n",
      "|      AAL1640|    AAL|            ORD|              LAX|10/22/22 05:52:00 AM|  10/22/22 09:36:42 AM|10/22/22 09:18:37 AM|  false|       N/A|  1744.0|\n",
      "|       DAL950|    DAL|            DTW|              LAS|10/22/22 06:35:00 AM|  10/22/22 10:10:55 AM|10/22/22 09:56:58 AM|  false|       N/A|  1749.0|\n",
      "+-------------+-------+---------------+-----------------+--------------------+----------------------+--------------------+-------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flight_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('cs179g_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c08378ad6c07d120a4d4245f9b267779e1ab3289002ceb568db038a6234fccb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
